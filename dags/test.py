"""
test
DAG auto-generated by Astro Cloud IDE.
"""

from airflow.decorators import dag
from astro import sql as aql
import pandas as pd
import pendulum

import json
from pendulum import datetime

# added a comment 2
# and another one

from airflow.decorators import (
    dag,
    task,
)  # DAG and task decorators for interfacing with the TaskFlow API

@dag(
    # This defines how often your DAG will run, or the schedule by which your DAG runs. In this case, this DAG
    # will run daily
    schedule="@daily",
    # This DAG is set to run for the first time on January 1, 2023. Best practice is to use a static
    # start_date. Subsequent DAG runs are instantiated based on the schedule
    start_date=datetime(2023, 1, 1),
    # When catchup=False, your DAG will only run the latest run that would have been scheduled. In this case, this means
    # that tasks will not be run between January 1, 2023 and 30 mins ago. When turned on, this DAG's first
    # run will be for the next 30 mins, per the its schedule
    catchup=False,
    default_args={
        "retries": 2,  # If a task fails, it will retry 2 times.
    },
    tags=["example"],
)  # If set, this tag is shown in the DAG view of the Airflow UI


@aql.dataframe(task_id="python_1")
def python_1_func():
    """
    #### Extract task
    A simple "extract" task to get data ready for the rest of the
    pipeline. In this case, getting data is simulated by reading from a
    hardcoded JSON string.
    """
    data_string = '{"1001": 301.27, "1002": 433.21, "1003": 502.22}'
    
    order_data_dict = json.loads(data_string)
    return order_data_dict

@aql.dataframe(task_id="python_2")
def python_2_func():
    @task(
            multiple_outputs=True
        )  # multiple_outputs=True unrolls dictionaries into separate XCom values
        def transform(order_data_dict: dict):
            """
            #### Transform task
            A simple "transform" task which takes in the collection of order data and
            computes the total order value.
            """
            total_order_value = 0
    
            for value in order_data_dict.values():
                total_order_value += value
    
            return {"total_order_value": total_order_value}

@aql.dataframe(task_id="python_3")
def python_3_func():
     def load(total_order_value: float):
            """
            #### Load task
            A simple "load" task that takes in the result of the "transform" task and prints it out,
            instead of saving it to end user review
            """
    
            print(f"Total order value is: {total_order_value:.2f}")

@dag(
    schedule="0 0 * * *",
    start_date=pendulum.from_format("2023-08-02", "YYYY-MM-DD").in_tz("UTC"),
    catchup=False,
)
def test():
    python_1 = python_1_func()

    python_2 = python_2_func()

    python_3 = python_3_func()

    python_2 << python_1

    python_3 << python_2

dag_obj = test()
